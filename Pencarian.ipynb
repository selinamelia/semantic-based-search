{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analisis algoritma rabin dan algoritma elias omega code dalam pengamanan dan kompresi file teks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open (\"judulskripsi-cleaned.txt\", \"r\",encoding='utf-8') as file:\n",
    "    dataset=file.readlines()\n",
    "print(dataset[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "import os\n",
    "import gensim.models.word2vec as w2v\n",
    "from gensim.models import Word2Vec\n",
    "word2vec  = w2v.Word2Vec.load(os.path.join(\"trained\", \"W2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model mala\n",
    "import os\n",
    "import gensim.models.word2vec as w2v\n",
    "from gensim.models import Word2Vec\n",
    "word2vec  = w2v.Word2Vec.load(os.path.join(\"trained\", \"W2vec-mala.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from numpy.linalg import norm\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddvector(tokens, word2vec):\n",
    "    vector_kalimat = np.zeros(word2vec.layer1_size)\n",
    "    jumlahkata = 0\n",
    "    if len(tokens) > 1:\n",
    "        for i in tokens:\n",
    "            try:\n",
    "                vector = word2vec[i.strip()]\n",
    "                vector_kalimat = np.add(vector_kalimat,vector)\n",
    "                jumlahkata += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "        \n",
    "    elif len(tokens) == 1:\n",
    "        vector_kalimat = word2vec[tokens[0].strip()]\n",
    "        \n",
    "    return vector_kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kueri: algoritma djikstra \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `layer1_size` (Attribute will be removed in 4.0.0, use self.trainables.layer1_size instead).\n",
      "  \n",
      "C:\\Users\\Selina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.618688329692372"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_1 = 'algoritma djikstra '\n",
    "tokens_1 = word_tokenize(pattern_1)\n",
    "#print(tokens_1)\n",
    "print(\"Kueri:\", pattern_1)\n",
    "p1 = embeddvector(tokens_1, word2vec)\n",
    "norm(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `layer1_size` (Attribute will be removed in 4.0.0, use self.trainables.layer1_size instead).\n",
      "  \n",
      "C:\\Users\\Selina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algoritma affine cipher dan algoritma multi-factor rsa pada pengamanan citra digital dalam skema kriptografi hybrid\\n_0.8946943027195905', 'analisis algoritma massey-omura pada three pass protocol untuk pengamanan file berbasis android\\n_0.8128827203457333', 'analisis algoritma modified least significant bit fungsi polinomial untuk pengamanan citra digital\\n_0.8133916363918823', 'analisis algoritma rabin dan algoritma elias omega code dalam pengamanan dan kompresi file teks\\n_0.9032835730630582', 'analisis algoritma rsa dan algoritma elias omega code dalam keamanan dan kompresi file citra\\n_0.8735319469013428', 'analisis dan implementasi algoritma brute force dengan algoritma optimal mismatch pada aplikasi kamus bahasa indonesia-sunda\\n_0.8620101213025785', 'analisis dan implementasi kombinasi algoritma skipjack dan algoritma mcaliece pada pengamanan file teks\\n_0.9278371564741517', 'analisis dan perbandingan algoritma brute force dan algoritma horspool pada aplikasi kamus bahasa indonesia - mandarin\\n_0.8388030368902282', 'analisis dan perbandingan algoritma colussi dan algoritma simon dalam pencarian kata pada jurnal\\n_0.9121353252683037', 'analisis kinerja algoritma elias omega dan algoritma fixed length binary encoding pada kompresi file teks\\n_0.9065386416102993', 'analisis perbandingan algoritma minimax dan algoritma steepest ascent hill climbing dalam permainan tic tac toe\\n_0.9555165812317408', 'implementasi algoritma kriptografi myszkowski transposition, beaufort cipher, dan algoritma kompresi goldbach code g1\\n_0.9549171318942179', 'implementasi algoritma kriptografi rail fence cipher dan algoritma myszkowski transposition dan algoritma kompresi fibonacci code\\n_0.9646048111270265', 'implementasi kriptanalisis kunci publik algoritma rabin dengan algoritma faktorisasi euler\\n_0.9536716494831095', 'implementasi kriptografi hybrid pada algoritma one time pad otp dan algoritma micali-goldwasser\\n_0.9653128670003415', 'implementasi sistem kriptokompresi dengan algoritma elgamal dan algoritma kompresi levenstein code\\n_0.9544555606113897', 'implementasi sistem kriptokompresi dengan algoritma rsa-crt dan algoritma kompresi elias delta\\n_0.9557424105180494', 'sistem kripto-kompresi dengan algoritma elgamal dan algoritma even-rodeh code\\n_0.9578344283120767']\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "\n",
    "hasil = []\n",
    "for i in dataset:\n",
    "    pattern_2= i\n",
    "    tokens_2 = word_tokenize(pattern_2)\n",
    "    #print(tokens_2)\n",
    "    p2 = embeddvector(tokens_2, word2vec)\n",
    "    np.dot(p1,p2)\n",
    "    norm(p2)\n",
    "    np.dot(norm(p1),norm(p2))\n",
    "    akurat = np.divide(np.dot(p1,p2),np.dot(norm(p1),norm(p2)))\n",
    " \n",
    "    if (akurat >=0.95):\n",
    "        #print(pattern_2, akurat)\n",
    "        s = pattern_2 + '_' + str(akurat)\n",
    "        hasil.append(s)\n",
    "    \n",
    "    if(len(hasil)<10):\n",
    "        if (akurat >=0.8):\n",
    "            #print(pattern_2, akurat)\n",
    "            s = pattern_2 + '_' + str(akurat)\n",
    "            hasil.append(s)\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `layer1_size` (Attribute will be removed in 4.0.0, use self.trainables.layer1_size instead).\n",
      "  \n",
      "C:\\Users\\Selina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analisa dan implementasi rdf resource description framework pada web semantik untuk pencarian berita\\n_0.6690529289073206', 'evaluasi penggunaan istilah komputer pada situs web pemerintahan republik indonesia\\n_0.547375978001349', 'implementasi resource description framework dalam semantic web berbasis ontologi pada sistem pencarian informasi obat\\n_0.6444265954921677', 'implementasi semantik web berbasis ontologi pada keterkaitan antar skripsi\\n_0.6459757744221094', 'implementasi web scraping pada web semantik berbasis ontologi untuk data obat dan penyakit\\n_0.7540737229305584', 'implementasi web scraping pada web semantik berbasis ontologi untuk data obat dan penyakit\\n_0.7540737229305584', 'integrasi kamus multibahasa menggunakan semantic web\\n_0.6791341217130923', 'membangun basis data leksikal bahasa indonesia berbasis wordnet bahasa inggris menggunakan semantik web\\n_0.6036901163092153', 'sistem monitoring cuaca dan identifikasi keadaan cuaca menggunakan teknik web scraping\\n_0.53967022762768', 'sistem pencarian obyek wisata di sumatera utara menggunakan semantic web berbasis ontologi\\n_0.5978176586397845']\n"
     ]
    }
   ],
   "source": [
    "#dataset mala\n",
    "\n",
    "hasil = []\n",
    "for i in dataset:\n",
    "    pattern_2= i\n",
    "    tokens_2 = word_tokenize(pattern_2)\n",
    "    #print(tokens_2)\n",
    "    p2 = embeddvector(tokens_2, word2vec)\n",
    "    np.dot(p1,p2)\n",
    "    norm(p2)\n",
    "    np.dot(norm(p1),norm(p2))\n",
    "    akurat = np.divide(np.dot(p1,p2),np.dot(norm(p1),norm(p2)))\n",
    " \n",
    "    if (akurat >=0.7):\n",
    "        #print(pattern_2, akurat)\n",
    "        s = pattern_2 + '_' + str(akurat)\n",
    "        hasil.append(s)\n",
    "    \n",
    "    if(len(hasil)<10):\n",
    "        if (akurat >=0.5):\n",
    "            #print(pattern_2, akurat)\n",
    "            s = pattern_2 + '_' + str(akurat)\n",
    "            hasil.append(s)\n",
    "print(hasil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyFile=open('hasilpencarian_kueri8.txt','w')\n",
    "MyFile.write(str(hasil))\n",
    "MyFile.write('\\n')\n",
    "MyFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analisa dan implementasi rdf resource description framework pada web semantik untuk pencarian berita\\n_0.6690529289073206'\n",
      " 'evaluasi penggunaan istilah komputer pada situs web pemerintahan republik indonesia\\n_0.547375978001349'\n",
      " 'implementasi resource description framework dalam semantic web berbasis ontologi pada sistem pencarian informasi obat\\n_0.6444265954921677'\n",
      " 'implementasi semantik web berbasis ontologi pada keterkaitan antar skripsi\\n_0.6459757744221094'\n",
      " 'implementasi web scraping pada web semantik berbasis ontologi untuk data obat dan penyakit\\n_0.7540737229305584'\n",
      " 'implementasi web scraping pada web semantik berbasis ontologi untuk data obat dan penyakit\\n_0.7540737229305584'\n",
      " 'integrasi kamus multibahasa menggunakan semantic web\\n_0.6791341217130923'\n",
      " 'membangun basis data leksikal bahasa indonesia berbasis wordnet bahasa inggris menggunakan semantik web\\n_0.6036901163092153'\n",
      " 'sistem monitoring cuaca dan identifikasi keadaan cuaca menggunakan teknik web scraping\\n_0.53967022762768'\n",
      " 'sistem pencarian obyek wisata di sumatera utara menggunakan semantic web berbasis ontologi\\n_0.5978176586397845']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'hasilpencarian_kueri8m.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    for line in f :\n",
    "        line = line.replace('\\n_', '').replace(',', '\\n')\n",
    "        print(line)\n",
    "    MyFile=open('hasilpencarian_kueri8m.txt','w') #file fix yg menampung url\n",
    "    MyFile.write(line)\n",
    "    MyFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spatial', 0.935913622379303),\n",
       " ('loss', 0.9315661787986755),\n",
       " ('high-pass', 0.930500864982605),\n",
       " ('gaussian', 0.9242162704467773),\n",
       " ('mereduksi', 0.9170271754264832),\n",
       " ('textrank', 0.9113767147064209),\n",
       " ('aturan', 0.9025701284408569),\n",
       " ('stego', 0.89924556016922),\n",
       " ('bulat', 0.8920992612838745),\n",
       " ('segmentation', 0.8919523358345032)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enkripsi', 0.7072241902351379),\n",
       " ('dekripsi.', 0.6150321960449219),\n",
       " ('dekripsinya', 0.5663092136383057),\n",
       " ('enkripsi-dekripsi', 0.5084726810455322),\n",
       " ('enkripsi.', 0.5020135641098022),\n",
       " ('pendekripsian', 0.49262794852256775),\n",
       " ('pengenkripsian', 0.49111348390579224),\n",
       " ('didekripsi', 0.46924060583114624),\n",
       " ('spritz.', 0.4462868571281433),\n",
       " ('dekripsinya.', 0.4449533522129059)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"dekripsi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bellman-ford', 0.6514387726783752),\n",
       " ('floyd-warshall', 0.5945824384689331),\n",
       " ('djikstra', 0.5815274119377136),\n",
       " ('bellman-ford.', 0.5663304924964905),\n",
       " ('s-ord', 0.5354865789413452),\n",
       " ('s-dijkstra', 0.5320544838905334),\n",
       " ('greedy', 0.5295776128768921),\n",
       " ('l-deque', 0.5049644708633423),\n",
       " ('prim', 0.49494048953056335),\n",
       " ('s-ord.', 0.48155900835990906)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"dijkstra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('algortima', 0.6938381195068359),\n",
       " ('metode', 0.5748728513717651),\n",
       " ('algorima', 0.47963863611221313),\n",
       " ('proses', 0.4212411642074585),\n",
       " ('algoritma.', 0.40521398186683655),\n",
       " ('teknik', 0.4019071161746979),\n",
       " ('padaalgoritma', 0.3936845660209656),\n",
       " ('algorithm', 0.3868470788002014),\n",
       " ('kunci', 0.3645487427711487),\n",
       " ('modifikasi', 0.35951536893844604)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"algoritma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dekompresi', 0.6803461313247681),\n",
       " ('kompresi.', 0.5906280279159546),\n",
       " ('terkompresi', 0.5013146996498108),\n",
       " ('dikompresi', 0.46183323860168457),\n",
       " ('pengkompresian', 0.4467647671699524),\n",
       " ('pemampatan', 0.42963165044784546),\n",
       " ('dekripsi', 0.4197404682636261),\n",
       " ('compression', 0.41415539383888245),\n",
       " ('kompresinya', 0.41236400604248047),\n",
       " ('mengkompresi', 0.4117678999900818)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"kompresi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
